{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Run this cell at the start of every new Colab session\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from google.colab import drive\n",
        "\n",
        "# --- Mount Google Drive ---\n",
        "drive.mount('/content/drive')\n",
        "print(\"Drive mounted\")\n",
        "\n",
        "# --- Clone kits21 repo ---\n",
        "if not os.path.exists(\"/content/kits21\"):\n",
        "    !git clone https://github.com/neheller/kits21.git /content/kits21 -q\n",
        "    print(\"kits21 repo cloned\")\n",
        "else:\n",
        "    print(\"kits21 repo already exists\")\n",
        "\n",
        "# --- Install kits21 package ---\n",
        "%cd /content/kits21\n",
        "!pip install -e . -q\n",
        "print(\"kits21 package installed\")\n",
        "\n",
        "# --- Redirect TRAINING_DIR to Drive ---\n",
        "paths_file = \"/content/kits21/kits21/configuration/paths.py\"\n",
        "new_content = '''from pathlib import Path\n",
        "import os\n",
        "\n",
        "TRAINING_DIR = Path(\"/content/drive/MyDrive/kidney-tumour-detection/dataset/raw\")\n",
        "TESTING_DIR = Path(os.environ[\"KITS21_TEST_DIR\"]).resolve(strict=True) if \"KITS21_TEST_DIR\" in os.environ.keys() else None\n",
        "SRC_DIR = Path(os.environ[\"KITS21_SERVER_DATA\"]).resolve(strict=True) if \"KITS21_SERVER_DATA\" in os.environ.keys() else None\n",
        "CACHE_FILE = Path(__file__).parent.parent / \"annotation\" / \"cache.json\"\n",
        "'''\n",
        "with open(paths_file, \"w\") as f:\n",
        "    f.write(new_content)\n",
        "print(\"TRAINING_DIR redirected to Drive\")\n",
        "\n",
        "# --- Add kits21 to Python path ---\n",
        "sys.path.insert(0, \"/content/kits21\")\n",
        "\n",
        "# --- Verify everything is working ---\n",
        "from kits21.configuration.paths import TRAINING_DIR\n",
        "\n",
        "cases_on_drive = len([\n",
        "    c for c in os.listdir(str(TRAINING_DIR))\n",
        "    if c.startswith(\"case_\")\n",
        "])\n",
        "\n",
        "print(f\"\\n{'='*50}\")\n",
        "print(f\"TRAINING_DIR : {TRAINING_DIR}\")\n",
        "print(f\"Drive accessible: {os.path.exists(str(TRAINING_DIR))}\")\n",
        "print(f\"Cases on Drive: {cases_on_drive}/300\")\n",
        "print(f\"{'='*50}\")\n",
        "\n",
        "if cases_on_drive == 300:\n",
        "    print(\"Session ready - all 300 cases confirmed\")\n",
        "else:\n",
        "    print(\"Warning: Expected 300 cases, found\", cases_on_drive)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rgB6uh1LsBbv",
        "outputId": "9eb7cd54-88c3-40e5-ab7e-95c1aab1d109"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive mounted\n",
            "kits21 repo already exists\n",
            "/content/kits21\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "kits21 package installed\n",
            "TRAINING_DIR redirected to Drive\n",
            "\n",
            "==================================================\n",
            "TRAINING_DIR : /content/drive/MyDrive/kidney-tumour-detection/dataset/raw\n",
            "Drive accessible: True\n",
            "Cases on Drive: 300/300\n",
            "==================================================\n",
            "Session ready - all 300 cases confirmed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "CX0S48psIuWT",
        "outputId": "54976229-2469-4afe-a91f-c5e03cbfb1b7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-550523994.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# --- Mount Google Drive ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Google Drive mounted.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "# DRIVE MOUNT AND ENVIRONMENT VERIFICATION\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# --- Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted.\")\n",
        "\n",
        "# --- Verify project folder exists on Drive ---\n",
        "PROJECT_ROOT = '/content/drive/MyDrive/kidney-tumour-detection'\n",
        "\n",
        "required_folders = [\n",
        "    'dataset/raw',\n",
        "    'dataset/processed',\n",
        "    'checkpoints',\n",
        "    'logs',\n",
        "    'outputs'\n",
        "]\n",
        "\n",
        "print(\"Verifying folder structure...\")\n",
        "all_good = True\n",
        "for folder in required_folders:\n",
        "  full_path = os.path.join(PROJECT_ROOT, folder)\n",
        "  if os.path.exists(full_path):\n",
        "    print(f\" {folder}\")\n",
        "  else:\n",
        "    print(f\" {folder} missing, creating it now...\")\n",
        "    os.mkdirs(full_path, exist_ok = True)\n",
        "    print(f\" {folder} created!\")\n",
        "    all_good = False\n",
        "\n",
        "if all_good:\n",
        "  print(\"All folders have been verified\")\n",
        "else:\n",
        "  print(\"Missing folders have been created\")\n",
        "\n",
        "# --- Check GPU availability ---\n",
        "import subprocess\n",
        "print(\"Checking GPU availability...\")\n",
        "try:\n",
        "  gpu_info = subprocess.run(\n",
        "      ['nvidia-smi'],\n",
        "      capture_output=True,\n",
        "      text=True\n",
        "      )\n",
        "  if gpu_info.returncode == 0:\n",
        "          for line in gpu_info.stdout.split('\\n'):\n",
        "              if any(x in line for x in ['Tesla', 'A100', 'T4', 'V100', 'L4']):\n",
        "                  print(f\" GPU detected: {line.strip()}\")\n",
        "  else:\n",
        "    print(\"nvidia-smi returned an error\")\n",
        "except FileNotFoundError:\n",
        "    print(\"No GPU detected - please change runtime type\")\n",
        "    print(\"Go to: Runtime → Change runtime type → T4 GPU\")\n",
        "except Exception as e:\n",
        "    print(f\" GPU check failed: {e}\")\n",
        "\n",
        "# --- Check RAM ---\n",
        "import psutil\n",
        "ram = psutil.virtual_memory()\n",
        "print(f\"RAM available: {ram.available / (1024**3):.1f} gb\"\n",
        "      f\"/ {ram.total / (1024**3):.1f} GB total\")\n",
        "\n",
        "# --- Check Runtime Disk Usage ---\n",
        "disk = psutil.disk_usage('/')\n",
        "print(f\"Runtime disk: {disk.free / (1024**3):.1f} GB free \"\n",
        "      f\"/ {disk.total / (1024**3):.1f} GB total\")\n",
        "print(\"Drive storage: 2TB (psutil cannot read network drives accurately)\")\n",
        "print(\"Verify manually at drive.google.com\")\n",
        "\n",
        "# --- Check Drive storage ---\n",
        "drive_disk = psutil.disk_usage(PROJECT_ROOT)\n",
        "print(f\"Drive storage: {drive_disk.free / (1024**3):.1f} GB free \"\n",
        "      f\"/ {drive_disk.total / (1024**3):.1f} GB total\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Session ready. Project root:\", PROJECT_ROOT)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GITHUB REPOSITORY SYNC\n",
        "\n",
        "import os\n",
        "\n",
        "GITHUB_REPO = \"https://github.com/danokundaye/kidney-tumour-detection.git\"\n",
        "REPO_NAME = \"kidney-tumour-detection\"\n",
        "CLONE_PATH = f\"/content/{REPO_NAME}\"\n",
        "\n",
        "# --- Clone or update repository ---\n",
        "if os.path.exists(CLONE_PATH):\n",
        "  print(\"Repository already exists, pulling latest changes...\")\n",
        "  os.chdir(CLONE_PATH)\n",
        "  os.system(\"git pull origin main\")\n",
        "  print(\"Repository updated\")\n",
        "else:\n",
        "  print(\"Cloning repository...\")\n",
        "  os.system(f\" git clone {GITHUB_REPO} {CLONE_PATH}\")\n",
        "  print(\"Repository cloned\")\n",
        "\n",
        "# --- Add repo to Python path so we can import our modules ---\n",
        "import sys\n",
        "if CLONE_PATH not in sys.path:\n",
        "    sys.path.insert(0, CLONE_PATH)\n",
        "    print(f\" Added {CLONE_PATH} to Python path\")\n",
        "\n",
        "print(f\"\\nWorking directory: {CLONE_PATH}\")\n",
        "print(\"GitHub sync complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTul3MwWJ1Hl",
        "outputId": "f65684ad-9151-46c0-f2ce-b400f4a49ab6",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository...\n",
            "Repository cloned\n",
            " Added /content/kidney-tumour-detection to Python path\n",
            "\n",
            "Working directory: /content/kidney-tumour-detection\n",
            "GitHub sync complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INSTALL REQUIRED LIBRARIES\n",
        "\n",
        "print(\"Installing required libraries...\")\n",
        "print(\"This will take 3-5 minutes. Stay calm.\")\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "  subprocess.check_call(\n",
        "      [sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"],\n",
        "      stdout=subprocess.DEVNULL,\n",
        "      stderr=subprocess.DEVNULL\n",
        "  )\n",
        "\n",
        "# Verify PyTorch has already been installed\n",
        "print(\" Checking PyTorch...\", end=\" \")\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"already installed (v{torch.__version__})\")\n",
        "    else:\n",
        "        print(\"Installed but no CUDA - check runtime type\")\n",
        "except ImportError:\n",
        "    print(\"Not found, installing...\")\n",
        "    subprocess.check_call(\n",
        "        [sys.executable, \"-m\", \"pip\", \"install\",\n",
        "         \"torch\", \"torchvision\", \"-q\"]\n",
        "    )\n",
        "    print(\"Installed\")\n",
        "\n",
        "libraries = [\n",
        "    (\"ultralytics\",                               \"YOLOv8\"),\n",
        "    (\"segmentation-models-pytorch\",               \"U-Net with ResNet50\"),\n",
        "    (\"monai\",                                     \"Medical imaging utilities\"),\n",
        "    (\"nibabel\",                                   \"NIfTI file reading\"),\n",
        "    (\"albumentations\",                            \"Data augmentation\"),\n",
        "    (\"shap\",                                      \"Explainability\"),\n",
        "    (\"opencv-python-headless\",                    \"Image processing\"),\n",
        "    (\"scikit-learn\",                              \"Metrics\"),\n",
        "    (\"matplotlib\",                                \"Matplotlib\"),\n",
        "    (\"seaborn\",                                   \"Seaborn\"),\n",
        "    (\"tqdm\",                                      \"Progress bars\"),\n",
        "]\n",
        "\n",
        "for package, name in libraries:\n",
        "  print(f\" Installing {name}...\", end=\" \")\n",
        "  try:\n",
        "    install(package)\n",
        "    print(\"installed\")\n",
        "  except Exception as e:\n",
        "    print(f\" Failed: {e}\")\n",
        "\n",
        "print(\"\\nVerifying critical imports...\")\n",
        "verification = {\n",
        "    \"torch\":                      \"PyTorch\",\n",
        "    \"torchvision\":                \"TorchVision\",\n",
        "    \"ultralytics\":                \"YOLOv8\",\n",
        "    \"segmentation_models_pytorch\":\"U-Net\",\n",
        "    \"monai\":                      \"MONAI\",\n",
        "    \"nibabel\":                    \"NiBabel\",\n",
        "    \"albumentations\":             \"Albumentations\",\n",
        "    \"shap\":                       \"SHAP\",\n",
        "    \"cv2\":                        \"OpenCV\",\n",
        "    \"sklearn\":                    \"Scikit-learn\",\n",
        "}\n",
        "\n",
        "all_imported = True\n",
        "for module, name in verification.items():\n",
        "  try:\n",
        "    __import__(module)\n",
        "    print(f\" {name}\")\n",
        "  except ImportError:\n",
        "    print(f\" {name} - FAILED TO IMPORT\")\n",
        "    all_imported = False\n",
        "\n",
        "if all_imported:\n",
        "    print(\"\\nAll libraries installed and verified\")\n",
        "else:\n",
        "    print(\"\\nSome libraries failed - rerun this cell\")\n",
        "\n",
        "# Verify PyTorch access to GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\")\n",
        "else:\n",
        "    print(\"CUDA not available - check runtime type\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK4C-z4AYUiS",
        "outputId": "3423ead2-df47-436e-df10-93b81baaae0e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required libraries...\n",
            "This will take 3-5 minutes. Stay calm.\n",
            " Checking PyTorch... already installed (v2.9.0+cu128)\n",
            " Installing YOLOv8... installed\n",
            " Installing U-Net with ResNet50... installed\n",
            " Installing Medical imaging utilities... installed\n",
            " Installing NIfTI file reading... installed\n",
            " Installing Data augmentation... installed\n",
            " Installing Explainability... installed\n",
            " Installing Image processing... installed\n",
            " Installing Metrics... installed\n",
            " Installing Matplotlib... installed\n",
            " Installing Seaborn... installed\n",
            " Installing Progress bars... installed\n",
            "\n",
            "Verifying critical imports...\n",
            " PyTorch\n",
            " TorchVision\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            " YOLOv8\n",
            " U-Net\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap_external>:1301: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " MONAI\n",
            " NiBabel\n",
            " Albumentations\n",
            " SHAP\n",
            " OpenCV\n",
            " Scikit-learn\n",
            "\n",
            "All libraries installed and verified\n",
            "GPU: Tesla T4\n",
            "VRAM: 14.6 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone official KiTS21 Repository\n",
        "\n",
        "import os\n",
        "\n",
        "# Define paths for download\n",
        "DRIVE_PROJECT = \"/content/drive/MyDrive/kidney-tumour-detection\"\n",
        "DATASET_RAW = os.path.join(DRIVE_PROJECT, \"dataset\", \"raw\")\n",
        "KITS_REPO = \"/content/kits21\" # Temporary code storage\n",
        "\n",
        "# Clone the KiTS21 repository into KITS_REPO\n",
        "if not os.path.exists(KITS_REPO):\n",
        "  !git clone https://github.com/neheller/kits21.git /content/kits21\n",
        "  print(\"KiTS21 repository successfully cloned!\")\n",
        "else:\n",
        "  print(\"KiTS21 repository already exists\")\n",
        "\n",
        "# Install package\n",
        "%cd /content/kits21\n",
        "!pip install -e . -q\n",
        "print(\"KiTS21 package installed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3f1KbGhtkCSf",
        "outputId": "af9c645d-1be8-4b18-c6d2-c1b2f3db108c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/kits21'...\n",
            "remote: Enumerating objects: 87173, done.\u001b[K\n",
            "remote: Counting objects: 100% (1155/1155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (571/571), done.\u001b[K\n",
            "^C\n",
            "KiTS21 repository successfully cloned!\n",
            "[Errno 2] No such file or directory: '/content/kits21'\n",
            "/content\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0mKiTS21 package installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Confirm number of cases\n",
        "cases = [item for item in os.listdir(\"/content/kits21/kits21/data\") if item.startswith(\"case_\")]\n",
        "print(f\"Total cases found: {len(cases)} \\n\")\n",
        "\n",
        "# Confirm case contents\n",
        "sample_case = \"/content/kits21/kits21/data/case_00000\"\n",
        "for item in os.listdir(sample_case):\n",
        "    print(f\"{item}\")\n",
        "\n",
        "# Confirm raw folder contents\n",
        "print(\"\\n--- raw folder ---\")\n",
        "raw_path = os.path.join(sample_case, \"raw\")\n",
        "for item in os.listdir(raw_path):\n",
        "    print(item)\n",
        "\n",
        "# Confirm segmentation folder contents\n",
        "print(\"\\n--- segmentations folder ---\")\n",
        "seg_path = os.path.join(sample_case, \"segmentations\")\n",
        "for item in os.listdir(seg_path):\n",
        "    print(item)\n",
        "\n",
        "download_path = \"/content/kits21/kits21/data\"\n",
        "# Check if there's a download script\n",
        "for root, dirs, files in os.walk(\"/content/kits21/kits21\"):\n",
        "    for file in files:\n",
        "        if \"download\" in file.lower():\n",
        "            print(os.path.join(root, file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "uVlQOJOPqw_p",
        "outputId": "45d826ea-c0d1-4461-e57d-6b8f2afe824b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/kits21/kits21/data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2003230403.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Confirm number of cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/kits21/kits21/data\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"case_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total cases found: {len(cases)} \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/kits21/kits21/data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redirect TRAINING_DIR to Google Drive to save downloads permanently\n",
        "paths_file = \"/content/kits21/kits21/configuration/paths.py\"\n",
        "\n",
        "new_content = '''from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Redirected to Google Drive for permanent storage\n",
        "TRAINING_DIR = Path(\"/content/drive/MyDrive/kidney-tumour-detection/dataset/raw\")\n",
        "TESTING_DIR = Path(os.environ[\"KITS21_TEST_DIR\"]).resolve(strict=True) if \"KITS21_TEST_DIR\" in os.environ.keys() else None\n",
        "SRC_DIR = Path(os.environ[\"KITS21_SERVER_DATA\"]).resolve(strict=True) if \"KITS21_SERVER_DATA\" in os.environ.keys() else None\n",
        "CACHE_FILE = Path(__file__).parent.parent / \"annotation\" / \"cache.json\"\n",
        "'''\n",
        "\n",
        "with open(paths_file, \"w\") as f:\n",
        "    f.write(new_content)\n",
        "\n",
        "print(\"TRAINING_DIR redirected to Drive\")\n",
        "\n",
        "# Verify the change\n",
        "with open(paths_file, \"r\") as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "h3ZyBXizrfeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy existing case folders in Temporary Storage to Google Drive\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_DIR = \"/content/kits21/kits21/data\"\n",
        "DEST_DIR = \"/content/drive/MyDrive/kidney-tumour-detection/dataset/raw\"\n",
        "\n",
        "# Get all case folders\n",
        "cases = sorted([c for c in os.listdir(SOURCE_DIR) if c.startswith(\"case_\")])\n",
        "print(f\"Cases to copy: {len(cases)}\")\n",
        "\n",
        "for case in tqdm(cases, desc=\"Copying cases to Drive\"):\n",
        "    src = os.path.join(SOURCE_DIR, case)\n",
        "    dst = os.path.join(DEST_DIR, case)\n",
        "\n",
        "    # Only copy if not already in Drive\n",
        "    if not os.path.exists(dst):\n",
        "      shutil.copytree(src, dst)\n",
        "\n",
        "print(f\"\\n All cases copied to Drive\")\n",
        "print(f\"Contents of Drive raw folder:\")\n",
        "print(len(os.listdir(DEST_DIR)), \"items\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gbp3mmsp4dV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify all 300 cases and their contents are on Drive\n",
        "\n",
        "import os\n",
        "\n",
        "DEST_DIR = \"/content/drive/MyDrive/kidney-tumour-detection/dataset/raw\"\n",
        "\n",
        "# Count case folders\n",
        "cases_on_drive = sorted([\n",
        "    item for item in os.listdir(DEST_DIR)\n",
        "    if item.startswith(\"case_\")\n",
        "])\n",
        "\n",
        "print(f\"Total case folders on Drive: {len(cases_on_drive)}\")\n",
        "print(f\"First case: {cases_on_drive[0]}\")\n",
        "print(f\"Last case: {cases_on_drive[-1]}\")\n",
        "\n",
        "# Also verify case_00000 has its contents\n",
        "sample = os.path.join(DEST_DIR, \"case_00000\")\n",
        "print(f\"\\nContents of case_00000 on Drive:\")\n",
        "for item in os.listdir(sample):\n",
        "    print(f\"  {item}\")"
      ],
      "metadata": {
        "id": "S5DOJIi0__Ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download CT Scans to Drive\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/kits21\")\n",
        "\n",
        "from pathlib import Path\n",
        "from kits21.configuration.paths import TRAINING_DIR\n",
        "import requests\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Verify TRAINING_DIR destination in Drive\n",
        "print(f\"Download destination: {TRAINING_DIR}\")\n",
        "assert \"drive\" in str(TRAINING_DIR), \"TRAINING_DIR is not pointing to Drive! Stop and fix this.\"\n",
        "\n",
        "imaging_url = \"https://kits19.sfo2.digitaloceanspaces.com/\"\n",
        "imaging_name_tmplt =  \"master_{:05d}.nii.gz\"\n",
        "temp_f = Path(\"/content/temp.tmp\")\n",
        "\n",
        "def get_destination(i):\n",
        "    return TRAINING_DIR / \"case_{:05d}\".format(i) / \"imaging.nii.gz\"\n",
        "\n",
        "def download_case(cid):\n",
        "   remote_name = imaging_name_tmplt.format(cid)\n",
        "   url = imaging_url + remote_name\n",
        "   dst = get_destination(cid)\n",
        "   try:\n",
        "    with requests.get(url, stream = True) as r:\n",
        "      r.raise_for_status()\n",
        "      with temp_f.open('wb') as f:\n",
        "        shutil.copyfileobj(r.raw, f)\n",
        "    shutil.move(str(temp_f), str(dst))\n",
        "    return True\n",
        "   except Exception as e:\n",
        "    if temp_f.exists():\n",
        "      temp_f.unlink()\n",
        "    print(f\"\\n Case {cid:05d} failed: {e}\")\n",
        "    return False\n",
        "\n",
        "# Find cases still needing download\n",
        "left_to_download = []\n",
        "for i in range(300):\n",
        "  dst = get_destination(i)\n",
        "  if not dst.exists():\n",
        "    left_to_download.append(i)\n",
        "\n",
        "print(f\"Cases already downloaded: {300 - len(left_to_download)}\")\n",
        "print(f\"Cases remaining: {len(left_to_download)}\")\n",
        "print(f\"Starting download...\\n\")\n",
        "\n",
        "failed = []\n",
        "for i, cid in enumerate(tqdm(left_to_download, desc=\"Downloading CT scans\")):\n",
        "    success = download_case(cid)\n",
        "    if not success:\n",
        "        failed.append(cid)\n",
        "\n",
        "print(f\"\\n Download complete\")\n",
        "print(f\"Successful: {len(left_to_download) - len(failed)}\")\n",
        "print(f\"Failed: {len(failed)}\")\n",
        "if failed:\n",
        "    print(f\"Failed cases: {failed}\")"
      ],
      "metadata": {
        "id": "UfElrHmGsHfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4.1: Pull latest and Run Data Exploration\n",
        "\n",
        "!cd /content/kidney-tumour-detection && git pull origin main\n",
        "\n",
        "import subprocess\n",
        "result = subprocess.run(\n",
        "    [\"python\", \"/content/kidney-tumour-detection/src/preprocessing/data_exploration.py\"],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "print(result.stdout)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WiQCGp22qQv4",
        "outputId": "fde2a804-1066-422a-9465-d3d2fc22f08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "KiTS21 DATASET EXPLORATION\n",
            "\n",
            "==================================================\n",
            "Dataset root: /content/drive/MyDrive/kidney-tumour-detection/dataset/raw\n",
            "Logs output:  /content/drive/MyDrive/kidney-tumour-detection/outputs/logs\n",
            "\n",
            "==================================================\n",
            "Step 1: File Integrity Check\n",
            "\n",
            "Total cases expected:        300\n",
            "Folders found:               300\n",
            "Imaging files found:         300\n",
            "Segmentation files found:    300\n",
            "Successfully loaded (both):  300\n",
            "\n",
            "All cases passed integrity check\n",
            "\n",
            "==================================================\n",
            "Step 2: Slice Count Distribution\n",
            "Min slices:    512\n",
            "Max slices:    796\n",
            "Mean slices:   512.95\n",
            "Median slices: 512.00\n",
            "Std deviation: 16.40\n",
            "\n",
            "All cases have 50+ slices\n",
            "\n",
            "==================================================\n",
            "Step 3: Intensity Statistics (sample of 20 cases)\n",
            "\n",
            "Global intensity min:  -2048.0 HU\n",
            "Global intensity max:  3071.0 HU\n",
            "Mean of case means:    -551.6 HU\n",
            "Mean of case stds:     545.8 HU\n",
            "5th percentile min:    -2048.0 HU\n",
            "95th percentile max:   3071.0 HU\n",
            "\n",
            "Config window range:   -79 to 304 HU\n",
            "→ Review if global min/max suggests a different window is needed\n",
            "\n",
            "==================================================\n",
            "Step 4: Segmentation Label Analysis (sample of 50 cases)\n",
            "\n",
            "Out of 50 sampled cases:\n",
            "Has kidney label (1): 50 (100.0%)\n",
            "Has tumour label  (2): 50 (100.0%)\n",
            "Has cyst label   (3): 24 (48.0%)\n",
            "\n",
            "All sampled cases have kidney label\n",
            "\n",
            "==================================================\n",
            "Step 5: Histology Label Analysis\n",
            "Loaded kits.json: 300 cases\n",
            "\n",
            "Histology label distribution:\n",
            "  Malignant : 275\n",
            "  Benign    : 25\n",
            "  Missing   : 0\n",
            "  Total     : 300\n",
            "\n",
            "==================================================\n",
            "Step 6: Saving Report\n",
            "Integrity report saved: /content/drive/MyDrive/kidney-tumour-detection/outputs/logs/exploration_integrity.csv\n",
            "Label report saved: /content/drive/MyDrive/kidney-tumour-detection/outputs/logs/exploration_labels.csv\n",
            "Metadata saved:  /content/drive/MyDrive/kidney-tumour-detection/outputs/logs/exploration_metadata.csv\n",
            "Intensity stats saved:  /content/drive/MyDrive/kidney-tumour-detection/outputs/logs/exploration_intensity_stats.txt\n",
            "\n",
            "All reports saved to: /content/drive/MyDrive/kidney-tumour-detection/outputs/logs\n",
            "\n",
            "==================================================\n",
            "Successful Data Exploration\n",
            "==================================================\n",
            "Review the output above before proceeding to Patient-Level Splitting\n",
            "Key things to confirm:\n",
            "  1. All 300 cases loaded successfully\n",
            "  2. Intensity range aligns with config window (-79 to 304 HU)\n",
            "  3. Note how many cases have tumour labels (label 2)\n",
            "  4. Note how many cases have confirmed histology labels\n",
            "\n",
            "ERRORS:\n",
            "\n",
            "Checking cases...:   0%|          | 0/300 [00:00<?, ?it/s]\n",
            "Checking cases...:   2%|▏         | 6/300 [00:00<00:05, 50.16it/s]\n",
            "Checking cases...:   4%|▍         | 12/300 [00:02<01:04,  4.45it/s]\n",
            "Checking cases...:   5%|▌         | 15/300 [00:04<01:41,  2.82it/s]\n",
            "Checking cases...:   8%|▊         | 23/300 [00:06<01:23,  3.32it/s]\n",
            "Checking cases...:  10%|█         | 31/300 [00:06<00:47,  5.64it/s]\n",
            "Checking cases...:  13%|█▎        | 38/300 [00:06<00:31,  8.31it/s]\n",
            "Checking cases...:  15%|█▌        | 46/300 [00:06<00:20, 12.31it/s]\n",
            "Checking cases...:  17%|█▋        | 52/300 [00:10<00:54,  4.53it/s]\n",
            "Checking cases...:  19%|█▉        | 58/300 [00:10<00:39,  6.16it/s]\n",
            "Checking cases...:  22%|██▏       | 66/300 [00:10<00:25,  9.12it/s]\n",
            "Checking cases...:  24%|██▍       | 73/300 [00:10<00:18, 12.40it/s]\n",
            "Checking cases...:  27%|██▋       | 81/300 [00:10<00:12, 17.20it/s]\n",
            "Checking cases...:  30%|██▉       | 89/300 [00:10<00:09, 23.01it/s]\n",
            "Checking cases...:  32%|███▏      | 96/300 [00:10<00:07, 28.42it/s]\n",
            "Checking cases...:  34%|███▍      | 103/300 [00:10<00:05, 34.13it/s]\n",
            "Checking cases...:  37%|███▋      | 111/300 [00:10<00:04, 41.55it/s]\n",
            "Checking cases...:  40%|███▉      | 119/300 [00:11<00:03, 47.57it/s]\n",
            "Checking cases...:  42%|████▏     | 127/300 [00:11<00:03, 54.28it/s]\n",
            "Checking cases...:  45%|████▌     | 135/300 [00:11<00:02, 58.38it/s]\n",
            "Checking cases...:  48%|████▊     | 143/300 [00:14<00:19,  8.11it/s]\n",
            "Checking cases...:  50%|█████     | 151/300 [00:14<00:13, 11.11it/s]\n",
            "Checking cases...:  53%|█████▎    | 158/300 [00:14<00:09, 14.43it/s]\n",
            "Checking cases...:  55%|█████▌    | 166/300 [00:14<00:07, 19.02it/s]\n",
            "Checking cases...:  58%|█████▊    | 173/300 [00:14<00:05, 21.47it/s]\n",
            "Checking cases...:  60%|██████    | 181/300 [00:14<00:04, 27.63it/s]\n",
            "Checking cases...:  63%|██████▎   | 188/300 [00:14<00:03, 32.97it/s]\n",
            "Checking cases...:  65%|██████▌   | 195/300 [00:15<00:02, 38.75it/s]\n",
            "Checking cases...:  68%|██████▊   | 203/300 [00:15<00:02, 45.71it/s]\n",
            "Checking cases...:  70%|███████   | 210/300 [00:15<00:01, 49.30it/s]\n",
            "Checking cases...:  72%|███████▏  | 217/300 [00:19<00:15,  5.41it/s]\n",
            "Checking cases...:  75%|███████▍  | 224/300 [00:19<00:10,  7.41it/s]\n",
            "Checking cases...:  77%|███████▋  | 232/300 [00:19<00:06, 10.40it/s]\n",
            "Checking cases...:  80%|███████▉  | 239/300 [00:19<00:04, 13.76it/s]\n",
            "Checking cases...:  82%|████████▏ | 247/300 [00:19<00:02, 18.70it/s]\n",
            "Checking cases...:  85%|████████▍ | 254/300 [00:19<00:01, 23.59it/s]\n",
            "Checking cases...:  87%|████████▋ | 262/300 [00:20<00:01, 30.04it/s]\n",
            "Checking cases...:  90%|█████████ | 270/300 [00:20<00:00, 36.95it/s]\n",
            "Checking cases...:  93%|█████████▎| 278/300 [00:22<00:02,  9.98it/s]\n",
            "Checking cases...:  95%|█████████▌| 286/300 [00:22<00:01, 13.57it/s]\n",
            "Checking cases...:  98%|█████████▊| 293/300 [00:22<00:00, 17.39it/s]\n",
            "Checking cases...: 100%|██████████| 300/300 [00:25<00:00,  5.75it/s]\n",
            "Checking cases...: 100%|██████████| 300/300 [00:25<00:00, 11.64it/s]\n",
            "\n",
            "Computing intensity stats...:   0%|          | 0/20 [00:00<?, ?it/s]\n",
            "Computing intensity stats...:   5%|▌         | 1/20 [00:08<02:38,  8.32s/it]\n",
            "Computing intensity stats...:  10%|█         | 2/20 [00:09<01:14,  4.13s/it]\n",
            "Computing intensity stats...:  15%|█▌        | 3/20 [00:10<00:42,  2.53s/it]\n",
            "Computing intensity stats...:  20%|██        | 4/20 [00:11<00:32,  2.05s/it]\n",
            "Computing intensity stats...:  25%|██▌       | 5/20 [00:13<00:28,  1.90s/it]\n",
            "Computing intensity stats...:  30%|███       | 6/20 [00:15<00:27,  1.94s/it]\n",
            "Computing intensity stats...:  35%|███▌      | 7/20 [00:17<00:26,  2.07s/it]\n",
            "Computing intensity stats...:  40%|████      | 8/20 [00:18<00:20,  1.72s/it]\n",
            "Computing intensity stats...:  45%|████▌     | 9/20 [00:29<00:51,  4.66s/it]\n",
            "Computing intensity stats...:  50%|█████     | 10/20 [00:31<00:36,  3.70s/it]\n",
            "Computing intensity stats...:  55%|█████▌    | 11/20 [00:33<00:29,  3.23s/it]\n",
            "Computing intensity stats...:  60%|██████    | 12/20 [00:34<00:20,  2.57s/it]\n",
            "Computing intensity stats...:  65%|██████▌   | 13/20 [00:36<00:17,  2.44s/it]\n",
            "Computing intensity stats...:  70%|███████   | 14/20 [00:37<00:11,  1.98s/it]\n",
            "Computing intensity stats...:  75%|███████▌  | 15/20 [00:38<00:09,  1.84s/it]\n",
            "Computing intensity stats...:  80%|████████  | 16/20 [00:41<00:07,  1.95s/it]\n",
            "Computing intensity stats...:  85%|████████▌ | 17/20 [00:42<00:05,  1.72s/it]\n",
            "Computing intensity stats...:  90%|█████████ | 18/20 [00:43<00:03,  1.57s/it]\n",
            "Computing intensity stats...:  95%|█████████▌| 19/20 [00:43<00:01,  1.24s/it]\n",
            "Computing intensity stats...: 100%|██████████| 20/20 [00:53<00:00,  3.81s/it]\n",
            "Computing intensity stats...: 100%|██████████| 20/20 [00:53<00:00,  2.69s/it]\n",
            "\n",
            "Analysing labels...:   0%|          | 0/50 [00:00<?, ?it/s]\n",
            "Analysing labels...:   2%|▏         | 1/50 [00:06<05:21,  6.57s/it]\n",
            "Analysing labels...:   4%|▍         | 2/50 [00:07<02:35,  3.25s/it]\n",
            "Analysing labels...:   6%|▌         | 3/50 [00:07<01:30,  1.93s/it]\n",
            "Analysing labels...:   8%|▊         | 4/50 [00:08<01:07,  1.47s/it]\n",
            "Analysing labels...:  10%|█         | 5/50 [00:09<00:58,  1.29s/it]\n",
            "Analysing labels...:  12%|█▏        | 6/50 [00:11<01:10,  1.60s/it]\n",
            "Analysing labels...:  14%|█▍        | 7/50 [00:13<01:16,  1.77s/it]\n",
            "Analysing labels...:  16%|█▌        | 8/50 [00:14<01:01,  1.45s/it]\n",
            "Analysing labels...:  18%|█▊        | 9/50 [00:23<02:37,  3.84s/it]\n",
            "Analysing labels...:  20%|██        | 10/50 [00:25<02:04,  3.10s/it]\n",
            "Analysing labels...:  22%|██▏       | 11/50 [00:27<01:48,  2.79s/it]\n",
            "Analysing labels...:  24%|██▍       | 12/50 [00:28<01:23,  2.19s/it]\n",
            "Analysing labels...:  26%|██▌       | 13/50 [00:29<01:15,  2.04s/it]\n",
            "Analysing labels...:  28%|██▊       | 14/50 [00:30<00:58,  1.62s/it]\n",
            "Analysing labels...:  30%|███       | 15/50 [00:31<00:49,  1.42s/it]\n",
            "Analysing labels...:  32%|███▏      | 16/50 [00:32<00:48,  1.43s/it]\n",
            "Analysing labels...:  34%|███▍      | 17/50 [00:33<00:41,  1.27s/it]\n",
            "Analysing labels...:  36%|███▌      | 18/50 [00:34<00:37,  1.18s/it]\n",
            "Analysing labels...:  38%|███▊      | 19/50 [00:35<00:28,  1.08it/s]\n",
            "Analysing labels...:  40%|████      | 20/50 [00:43<01:33,  3.11s/it]\n",
            "Analysing labels...:  42%|████▏     | 21/50 [00:46<01:31,  3.16s/it]\n",
            "Analysing labels...:  44%|████▍     | 22/50 [00:46<01:05,  2.33s/it]\n",
            "Analysing labels...:  46%|████▌     | 23/50 [00:49<01:04,  2.39s/it]\n",
            "Analysing labels...:  48%|████▊     | 24/50 [00:52<01:04,  2.50s/it]\n",
            "Analysing labels...:  50%|█████     | 25/50 [00:53<00:53,  2.15s/it]\n",
            "Analysing labels...:  52%|█████▏    | 26/50 [00:56<00:59,  2.46s/it]\n",
            "Analysing labels...:  54%|█████▍    | 27/50 [00:59<00:58,  2.55s/it]\n",
            "Analysing labels...:  56%|█████▌    | 28/50 [01:06<01:26,  3.93s/it]\n",
            "Analysing labels...:  58%|█████▊    | 29/50 [01:12<01:33,  4.47s/it]\n",
            "Analysing labels...:  60%|██████    | 30/50 [01:13<01:08,  3.42s/it]\n",
            "Analysing labels...:  62%|██████▏   | 31/50 [01:14<00:51,  2.69s/it]\n",
            "Analysing labels...:  64%|██████▍   | 32/50 [01:15<00:38,  2.15s/it]\n",
            "Analysing labels...:  66%|██████▌   | 33/50 [01:20<00:53,  3.13s/it]\n",
            "Analysing labels...:  68%|██████▊   | 34/50 [01:21<00:39,  2.45s/it]\n",
            "Analysing labels...:  70%|███████   | 35/50 [01:22<00:29,  1.96s/it]\n",
            "Analysing labels...:  72%|███████▏  | 36/50 [01:23<00:23,  1.66s/it]\n",
            "Analysing labels...:  74%|███████▍  | 37/50 [01:23<00:17,  1.34s/it]\n",
            "Analysing labels...:  76%|███████▌  | 38/50 [01:24<00:14,  1.17s/it]\n",
            "Analysing labels...:  78%|███████▊  | 39/50 [01:26<00:14,  1.31s/it]\n",
            "Analysing labels...:  80%|████████  | 40/50 [01:27<00:13,  1.38s/it]\n",
            "Analysing labels...:  82%|████████▏ | 41/50 [01:36<00:33,  3.71s/it]\n",
            "Analysing labels...:  84%|████████▍ | 42/50 [01:37<00:22,  2.80s/it]\n",
            "Analysing labels...:  86%|████████▌ | 43/50 [01:38<00:16,  2.29s/it]\n",
            "Analysing labels...:  88%|████████▊ | 44/50 [01:40<00:12,  2.05s/it]\n",
            "Analysing labels...:  90%|█████████ | 45/50 [01:41<00:08,  1.70s/it]\n",
            "Analysing labels...:  92%|█████████▏| 46/50 [01:47<00:12,  3.19s/it]\n",
            "Analysing labels...:  94%|█████████▍| 47/50 [01:49<00:07,  2.66s/it]\n",
            "Analysing labels...:  96%|█████████▌| 48/50 [01:51<00:05,  2.65s/it]\n",
            "Analysing labels...:  98%|█████████▊| 49/50 [01:53<00:02,  2.40s/it]\n",
            "Analysing labels...: 100%|██████████| 50/50 [01:55<00:00,  2.18s/it]\n",
            "Analysing labels...: 100%|██████████| 50/50 [01:55<00:00,  2.31s/it]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull latest and run Step 4.2: Data Splitting\n",
        "\n",
        "!cd /content/kidney-tumour-detection && git pull origin main\n",
        "\n",
        "import subprocess\n",
        "result = subprocess.run(\n",
        "    [\"python\", \"/content/kidney-tumour-detection/src/preprocessing/data_splitting.py\"],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"STDERR:\")\n",
        "    print(result.stderr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hyfchO0G4nU_",
        "outputId": "5fe373f6-cec3-4230-f521-83eacaf06797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/danokundaye/kidney-tumour-detection\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "\n",
            " Patient-level Data Splitting\n",
            "\n",
            "Strategy : Stratified by malignant label\n",
            "Seed     : 42\n",
            "Split    : 110 detection / 120 segmentation / 70 test\n",
            "\n",
            "Total cases loaded: 300\n",
            " Malignant: 275\n",
            " Benign:    25\n",
            "\n",
            " Splits must sum to 300. 300 splits confirmed.\n",
            "==================================================\n",
            "Patient-level Split Summary\n",
            "\n",
            "Detection Train (110 cases):\n",
            "   Malignant : 101 (91.8)\n",
            "   Benign    : 9 (8.2)\n",
            "\n",
            "Segmentation Train (120 cases):\n",
            "   Malignant : 110 (91.7)\n",
            "   Benign    : 10 (8.3)\n",
            "\n",
            "Test (70 cases):\n",
            "   Malignant : 64 (91.4)\n",
            "   Benign    : 6 (8.6)\n",
            "\n",
            " Uniqueness Check\n",
            "  Total cases assigned : 300\n",
            "  Unique case IDs      : 300\n",
            "  No overlaps detected : PASS\n",
            "\n",
            "Splits saved to: /content/drive/MyDrive/kidney-tumour-detection/dataset/processed/splits\n",
            "  detection_train.csv    (110 cases)\n",
            "  segmentation_train.csv (120 cases)\n",
            "  test.csv               (70 cases)\n",
            "  split_summary.txt\n",
            "Splitting Complete \n",
            "\n",
            "Do NOT modify the split CSVs manually after this point.\n",
            "All subsequent scripts read from these files.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/kidney-tumour-detection && git pull origin main\n",
        "\n",
        "# Single Slice Extraction Test\n",
        "import subprocess\n",
        "result = subprocess.run(\n",
        "    [\"python\", \"-c\", \"\"\"\n",
        "import yaml\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.insert(0, '/content/kidney-tumour-detection/src/preprocessing')\n",
        "from slice_extraction import process_case\n",
        "\n",
        "with open('/content/kidney-tumour-detection/configs/config.yaml', 'r') as f:\n",
        "    import yaml\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "dataset_root = Path(config['paths']['dataset_root'])\n",
        "slices_dir   = Path(config['paths']['slices_dir'])\n",
        "window_min   = config['preprocessing']['ct_window_min']\n",
        "window_max   = config['preprocessing']['ct_window_max']\n",
        "\n",
        "# Re-process the test case (will overwrite previous test output)\n",
        "test_case  = 'case_00000'\n",
        "output_dir = slices_dir / 'test_single_case'\n",
        "\n",
        "result = process_case(\n",
        "    case_id      = test_case,\n",
        "    dataset_root = dataset_root,\n",
        "    output_dir   = output_dir,\n",
        "    window_min   = window_min,\n",
        "    window_max   = window_max,\n",
        "    kidney_only  = False\n",
        ")\n",
        "\n",
        "print(f\"Total slices : {result['total_slices']}\")\n",
        "print(f\"Saved slices : {result['saved_slices']}\")\n",
        "\n",
        "# Check a MIDDLE slice instead of the first one\n",
        "images_dir  = output_dir / test_case / 'images'\n",
        "masks_dir   = output_dir / test_case / 'masks'\n",
        "all_images  = sorted(images_dir.glob('*.png'))\n",
        "\n",
        "# Pick slice 250 (middle of a 512-slice volume)\n",
        "mid_img  = np.array(Image.open(all_images[250]))\n",
        "mid_mask = np.array(Image.open(masks_dir / all_images[250].name))\n",
        "\n",
        "print(f\"\\\\nMiddle slice ({all_images[250].name}):\")\n",
        "print(f\"  Image - min: {mid_img.min()}, max: {mid_img.max()}, dtype: {mid_img.dtype}\")\n",
        "print(f\"  Mask  - unique values: {np.unique(mid_mask).tolist()}\")\n",
        "\"\"\"],\n",
        "    capture_output=True,\n",
        "    text=True\n",
        ")\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"STDERR:\")\n",
        "    print(result.stderr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wlMPRmBrXP59",
        "outputId": "1e0d90db-0c42-4150-b5ad-55b3f6b3b938"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/danokundaye/kidney-tumour-detection\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "Total slices : 512\n",
            "Saved slices : 512\n",
            "\n",
            "Middle slice (slice_0250.png):\n",
            "  Image - min: 0, max: 255, dtype: uint8\n",
            "  Mask  - unique values: [0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find a slice with actual kidney content and check its mask\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from pathlib import Path\n",
        "\n",
        "seg_path = Path(\"/content/drive/MyDrive/kidney-tumour-detection/dataset/raw/case_00000/aggregated_MAJ_seg.nii.gz\")\n",
        "seg_data = np.round(nib.load(str(seg_path)).get_fdata()).astype(np.uint8)\n",
        "\n",
        "# Find all slices with non-zero labels\n",
        "kidney_slices = []\n",
        "for i in range(seg_data.shape[2]):\n",
        "    unique = np.unique(seg_data[:, :, i]) # reveals the number of values/masks\n",
        "    if len(unique) > 1:  # more than just background\n",
        "        kidney_slices.append((i, unique.tolist()))\n",
        "\n",
        "print(f\"Slices with organ content: {len(kidney_slices)}\")\n",
        "print(f\"\\nFirst 5:\")\n",
        "for idx, labels in kidney_slices[:5]:\n",
        "    print(f\"  slice_{idx:04d}: {labels}\")\n",
        "print(f\"\\nLast 5:\")\n",
        "for idx, labels in kidney_slices[-5:]:\n",
        "    print(f\"  slice_{idx:04d}: {labels}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Tw3jkiJOazjC",
        "outputId": "bcedcceb-7d6e-4220-b910-774b212bbce2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slices with organ content: 151\n",
            "\n",
            "First 5:\n",
            "  slice_0139: [0, 1]\n",
            "  slice_0140: [0, 1]\n",
            "  slice_0141: [0, 1]\n",
            "  slice_0142: [0, 1]\n",
            "  slice_0143: [0, 1]\n",
            "\n",
            "Last 5:\n",
            "  slice_0361: [0, 1]\n",
            "  slice_0362: [0, 1]\n",
            "  slice_0363: [0, 1]\n",
            "  slice_0364: [0, 1]\n",
            "  slice_0365: [0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Check the saved mask for slice_0139 (first kidney slice)\n",
        "mask_path = Path(\"/content/drive/MyDrive/kidney-tumour-detection/dataset/processed/slices/test_single_case/case_00000/masks/slice_0139.png\")\n",
        "\n",
        "mask = np.array(Image.open(mask_path))\n",
        "print(f\"Mask unique values: {np.unique(mask).tolist()}\")\n",
        "print(f\"Expected          : [0, 85]\")\n",
        "print(f\"  0  = background\")\n",
        "print(f\"  85 = kidney (1 × 85)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FC1l9u8bcR_I",
        "outputId": "920a5315-15c4-48f5-bab6-51e3df798e32"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mask unique values: [0, 85]\n",
            "Expected          : [0, 85]\n",
            "  0  = background\n",
            "  85 = kidney (1 × 85)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4.3: Full Slice Extraction\n",
        "!python /content/kidney-tumour-detection/src/preprocessing/slice_extraction.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iSOL2lwKcvBc",
        "outputId": "31c8792f-fdb6-415e-ec38-e2f4eae4f642"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Slice Extraction\n",
            "Dataset root : /content/drive/MyDrive/kidney-tumour-detection/dataset/raw\n",
            "Output dir   : /content/drive/MyDrive/kidney-tumour-detection/dataset/processed/slices\n",
            "CT window    : [-79, 304] HU\n",
            "\n",
            "Processing:       Detection_train\n",
            "Kidney-only filter: False\n",
            "Total cases    : 110\n",
            "Already done   : 110\n",
            "To process     : 0\n",
            "All cases already processed. Skipping.\n",
            "\n",
            "Processing:       Segmentation_train\n",
            "Kidney-only filter: True\n",
            "Total cases    : 120\n",
            "Already done   : 120\n",
            "To process     : 0\n",
            "All cases already processed. Skipping.\n",
            "\n",
            "Processing:       Test\n",
            "Kidney-only filter: False\n",
            "Total cases    : 70\n",
            "Already done   : 50\n",
            "To process     : 20\n",
            "Extracting test: 100% 20/20 [07:14<00:00, 21.73s/it]\n",
            "\n",
            "test summary:\n",
            "  Cases processed  : 20\n",
            "  Total slices     : 10240\n",
            "  Saved slices     : 10240\n",
            "  Skipped slices   : 0\n",
            "  Avg saved/case   : 512.0\n",
            "\n",
            " Slice extraction complete\n",
            "Check your Drive for processed/slices/\n",
            "Verify a few slices visually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete and re-slice case_00261 due to mismatch in image and mask (79, 78)\n",
        "import shutil\n",
        "import yaml\n",
        "import sys\n",
        "from pathlib import Path\n",
        "sys.path.insert(0, '/content/kidney-tumour-detection/src/preprocessing')\n",
        "from slice_extraction import process_case\n",
        "\n",
        "with open('/content/kidney-tumour-detection/configs/config.yaml', 'r') as f:\n",
        "    import yaml\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "slices_dir   = Path(config['paths']['slices_dir'])\n",
        "dataset_root = Path(config['paths']['dataset_root'])\n",
        "window_min   = config['preprocessing']['ct_window_min']\n",
        "window_max   = config['preprocessing']['ct_window_max']\n",
        "\n",
        "case_id    = 'case_00261'\n",
        "output_dir = slices_dir / 'detection_train'\n",
        "case_dir   = output_dir / case_id\n",
        "\n",
        "# Delete incomplete folder\n",
        "shutil.rmtree(case_dir)\n",
        "print(f\"Deleted: {case_dir}\")\n",
        "\n",
        "# Reprocess\n",
        "result = process_case(\n",
        "    case_id      = case_id,\n",
        "    dataset_root = dataset_root,\n",
        "    output_dir   = output_dir,\n",
        "    window_min   = window_min,\n",
        "    window_max   = window_max,\n",
        "    kidney_only  = False\n",
        ")\n",
        "\n",
        "# Verify\n",
        "images_count = len(list((output_dir / case_id / 'images').glob('*.png')))\n",
        "masks_count  = len(list((output_dir / case_id / 'masks').glob('*.png')))\n",
        "print(f\"Images : {images_count}\")\n",
        "print(f\"Masks  : {masks_count}\")\n",
        "print(f\"Match  : {images_count == masks_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-hbn4a-rXdkU",
        "outputId": "bdb77529-739f-43f0-a7d5-c9babfd6da7d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted: /content/drive/MyDrive/kidney-tumour-detection/dataset/processed/slices/detection_train/case_00261\n",
            "Images : 512\n",
            "Masks  : 512\n",
            "Match  : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drive File Verification — Check slice extraction completeness\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "slices_dir = Path(\"/content/drive/MyDrive/kidney-tumour-detection/dataset/processed/slices\")\n",
        "splits_dir = Path(\"/content/drive/MyDrive/kidney-tumour-detection/dataset/processed/splits\")\n",
        "\n",
        "splits = {\n",
        "    \"detection_train\"   : splits_dir / \"detection_train.csv\",\n",
        "    \"segmentation_train\": splits_dir / \"segmentation_train.csv\",\n",
        "    \"test\"              : splits_dir / \"test.csv\"\n",
        "}\n",
        "\n",
        "print(\"Drive Verification\")\n",
        "\n",
        "for split_name, csv_path in splits.items():\n",
        "    cases_df = pd.read_csv(csv_path)\n",
        "    case_ids = cases_df['case_id'].tolist()\n",
        "\n",
        "    complete   = []\n",
        "    incomplete = []\n",
        "    missing    = []\n",
        "\n",
        "    for case_id in case_ids:\n",
        "        images_dir = slices_dir / split_name / case_id / \"images\"\n",
        "        masks_dir  = slices_dir / split_name / case_id / \"masks\"\n",
        "\n",
        "        if not images_dir.exists():\n",
        "            missing.append(case_id)\n",
        "        else:\n",
        "            img_count  = len(list(images_dir.glob(\"*.png\")))\n",
        "            mask_count = len(list(masks_dir.glob(\"*.png\")))\n",
        "\n",
        "            if img_count == 0 or mask_count == 0:\n",
        "                incomplete.append((case_id, img_count, mask_count))\n",
        "            elif img_count != mask_count:\n",
        "                incomplete.append((case_id, img_count, mask_count))\n",
        "            else:\n",
        "                complete.append(case_id)\n",
        "\n",
        "    print(f\"\\n{split_name.upper()}\")\n",
        "    print(f\"  Expected  : {len(case_ids)} cases\")\n",
        "    print(f\"  Complete  : {len(complete)} cases\")\n",
        "    print(f\"  Incomplete: {len(incomplete)} cases\")\n",
        "    print(f\"  Missing   : {len(missing)} cases\")\n",
        "\n",
        "    if incomplete:\n",
        "        print(f\"\\n  Incomplete cases (case_id, images, masks):\")\n",
        "        for item in incomplete:\n",
        "            print(f\"    {item}\")\n",
        "\n",
        "    if missing:\n",
        "        print(f\"\\n  Missing cases:\")\n",
        "        for case_id in missing:\n",
        "            print(f\"    {case_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OHDszmy3yDtz",
        "outputId": "d4005fc6-4d50-4871-fea2-e30d2672059f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive Verification\n",
            "\n",
            "DETECTION_TRAIN\n",
            "  Expected  : 110 cases\n",
            "  Complete  : 110 cases\n",
            "  Incomplete: 0 cases\n",
            "  Missing   : 0 cases\n",
            "\n",
            "SEGMENTATION_TRAIN\n",
            "  Expected  : 120 cases\n",
            "  Complete  : 120 cases\n",
            "  Incomplete: 0 cases\n",
            "  Missing   : 0 cases\n",
            "\n",
            "TEST\n",
            "  Expected  : 70 cases\n",
            "  Complete  : 70 cases\n",
            "  Incomplete: 0 cases\n",
            "  Missing   : 0 cases\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Pull latest changes and run Step 4.4: YOLO Label Generation\n",
        "!cd /content/kidney-tumour-detection && git pull origin main\n",
        "\n",
        "!python /content/kidney-tumour-detection/src/preprocessing/yolo_label_generation.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "U9KnP2J1S4QP",
        "outputId": "6a270c6c-57d5-4dc7-e832-21c12ed6c13e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/13)\u001b[K\rremote: Counting objects:  15% (2/13)\u001b[K\rremote: Counting objects:  23% (3/13)\u001b[K\rremote: Counting objects:  30% (4/13)\u001b[K\rremote: Counting objects:  38% (5/13)\u001b[K\rremote: Counting objects:  46% (6/13)\u001b[K\rremote: Counting objects:  53% (7/13)\u001b[K\rremote: Counting objects:  61% (8/13)\u001b[K\rremote: Counting objects:  69% (9/13)\u001b[K\rremote: Counting objects:  76% (10/13)\u001b[K\rremote: Counting objects:  84% (11/13)\u001b[K\rremote: Counting objects:  92% (12/13)\u001b[K\rremote: Counting objects: 100% (13/13)\u001b[K\rremote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)\u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 7 (delta 5), reused 7 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  14% (1/7)\rUnpacking objects:  28% (2/7)\rUnpacking objects:  42% (3/7)\rUnpacking objects:  57% (4/7)\rUnpacking objects:  71% (5/7)\rUnpacking objects:  85% (6/7)\rUnpacking objects: 100% (7/7)\rUnpacking objects: 100% (7/7), 809 bytes | 134.00 KiB/s, done.\n",
            "From https://github.com/danokundaye/kidney-tumour-detection\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   b14a8b7..53d91ab  main       -> origin/main\n",
            "Updating b14a8b7..53d91ab\n",
            "Fast-forward\n",
            " configs/config.yaml                        |  1 \u001b[31m-\u001b[m\n",
            " src/preprocessing/yolo_label_generation.py | 28 \u001b[32m+++++++++++++\u001b[m\u001b[31m---------------\u001b[m\n",
            " 2 files changed, 13 insertions(+), 16 deletions(-)\n",
            "YOLO label generation\n",
            "==================================================\n",
            "Slices dir  : /content/drive/MyDrive/kidney-tumour-detection/dataset/processed/slices\n",
            "Image size  : 512 x 512\n",
            "Min area    : 100 pixels\n",
            "\n",
            "Total cases    : 110\n",
            "Already done   : 0\n",
            "To process     : 110\n",
            "Generating YOLO labels: 100% 110/110 [16:53<00:00,  9.21s/it]\n",
            "\n",
            "YOLO Label Generation Summary:\n",
            "  Cases processed   : 110\n",
            "  Total slices      : 56604\n",
            "  Positive slices   : 20651\n",
            "  Empty slices      : 35953\n",
            "  Total boxes       : 21814\n",
            "  Avg boxes/positive: 1.06\n",
            "Label generation complete\n",
            "Verify a few label files manually:\n",
            "  - Positive slices should have 1-2 lines\n",
            "  - All values should be between 0 and 1\n",
            "  - Empty slices should have 0-byte .txt files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "slices_dir = Path(\"/content/drive/MyDrive/kidney-tumour-detection/dataset/processed/slices\")\n",
        "detection_dir = slices_dir / \"detection_train\"\n",
        "\n",
        "# Pick 3 random cases\n",
        "cases = sorted(detection_dir.iterdir())\n",
        "sample_cases = random.sample(cases, 3)\n",
        "\n",
        "for case_dir in sample_cases:\n",
        "    labels_dir = case_dir / \"labels\"\n",
        "    all_labels = sorted(labels_dir.glob(\"*.txt\"))\n",
        "\n",
        "    positive = [f for f in all_labels if f.stat().st_size > 0]\n",
        "    empty    = [f for f in all_labels if f.stat().st_size == 0]\n",
        "\n",
        "    print(f\"\\n{case_dir.name}\")\n",
        "    print(f\"  Total label files : {len(all_labels)}\")\n",
        "    print(f\"  Positive          : {len(positive)}\")\n",
        "    print(f\"  Empty             : {len(empty)}\")\n",
        "\n",
        "    # Show content of first positive label\n",
        "    if positive:\n",
        "        print(f\"  Sample ({positive[0].name}):\")\n",
        "        with open(positive[0]) as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                print(f\"    class={parts[0]}  cx={parts[1]}  cy={parts[2]}  w={parts[3]}  h={parts[4]}\")\n",
        "                # Verify values are in range\n",
        "                values = [float(x) for x in parts[1:]]\n",
        "                assert all(0.0 <= v <= 1.0 for v in values), \"VALUE OUT OF RANGE\"\n",
        "\n",
        "print(\"\\nAll checks passed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jrOgM-MOlFK8",
        "outputId": "0af96d59-699c-4bb8-95be-4c958f5aa6c1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "case_00297\n",
            "  Total label files : 512\n",
            "  Positive          : 153\n",
            "  Empty             : 359\n",
            "  Sample (slice_0136.txt):\n",
            "    class=0  cx=0.601562  cy=0.046875  w=0.074219  h=0.007812\n",
            "\n",
            "case_00238\n",
            "  Total label files : 512\n",
            "  Positive          : 174\n",
            "  Empty             : 338\n",
            "  Sample (slice_0127.txt):\n",
            "    class=0  cx=0.551758  cy=0.074219  w=0.087891  h=0.007812\n",
            "\n",
            "case_00104\n",
            "  Total label files : 512\n",
            "  Positive          : 167\n",
            "  Empty             : 345\n",
            "  Sample (slice_0110.txt):\n",
            "    class=0  cx=0.525391  cy=0.091797  w=0.058594  h=0.007812\n",
            "\n",
            "All checks passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "detection_dir = Path(\"/content/drive/MyDrive/kidney-tumour-detection/dataset/processed/slices/detection_train\")\n",
        "\n",
        "# Check first 3 cases\n",
        "for case_dir in sorted(detection_dir.iterdir())[:3]:\n",
        "    images  = (case_dir / \"images\").exists()\n",
        "    masks   = (case_dir / \"masks\").exists()\n",
        "    labels  = (case_dir / \"labels\").exists()\n",
        "\n",
        "    label_count = len(list((case_dir / \"labels\").glob(\"*.txt\"))) if labels else 0\n",
        "\n",
        "    print(f\"{case_dir.name}  images={images}  masks={masks}  labels={labels}  ({label_count} files)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RCK5xBTeKcGo",
        "outputId": "6c2f7fdc-21ef-4527-aa34-567bceb24235"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "case_00000  images=True  masks=True  labels=True  (512 files)\n",
            "case_00004  images=True  masks=True  labels=True  (512 files)\n",
            "case_00005  images=True  masks=True  labels=True  (512 files)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull latest changes and run Step 4.5: YOLO Dataset Structure\n",
        "!cd /content/kidney-tumour-detection && git pull origin main\n",
        "\n",
        "!python /content/kidney-tumour-detection/src/preprocessing/yolo_dataset_structure.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bBxXcz0WUfaJ",
        "outputId": "aac843f2-e41f-4e34-e361-42762cf62d9b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/danokundaye/kidney-tumour-detection\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n",
            "\n",
            "YOLO Dataset Structure\n",
            "\n",
            "Step 1: Splitting detection cases...\n",
            "  Malignant cases : 101\n",
            "  Benign cases    : 9\n",
            "  Train cases : 100\n",
            "  Val cases   : 10\n",
            "  Val set     : ['case_00034', 'case_00052', 'case_00089', 'case_00127', 'case_00193', 'case_00222', 'case_00233', 'case_00238', 'case_00267', 'case_00289']\n",
            "\n",
            "Step 2: Collecting image paths...\n",
            "  Train images : 51484\n",
            "  Val images   : 5120\n",
            "\n",
            "Step 3: Writing output files...\n",
            "  Written : /content/drive/MyDrive/kidney-tumour-detection/dataset/processed/splits/yolo_train.txt (51484 images)\n",
            "  Written : /content/drive/MyDrive/kidney-tumour-detection/dataset/processed/splits/yolo_val.txt (5120 images)\n",
            "  Written : /content/drive/MyDrive/kidney-tumour-detection/dataset/processed/splits/yolo_data.yaml\n",
            "\n",
            "Step 4: Verification checks...\n",
            "  Total images (train + val) : 56604 — matches Step 4.4? YES\n",
            "  Sample path exists         : YES\n",
            "  Sample                     : /content/drive/MyDrive/kidney-tumour-detection/dataset/processed/slices/detection_train/case_00000/images/slice_0000.png\n",
            "\n",
            "Step 4.5 complete.\n",
            "Next: Phase 5 — YOLOv8 Training\n"
          ]
        }
      ]
    }
  ]
}