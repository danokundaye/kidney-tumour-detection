{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX0S48psIuWT",
        "outputId": "067b190f-a393-42d3-9f8e-0da2f445497c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Google Drive mounted.\n",
            "Verifying folder structure...\n",
            " dataset/raw\n",
            " dataset/processed\n",
            " checkpoints\n",
            " logs\n",
            " outputs\n",
            "All folders have been verified\n",
            "Checking GPU availability...\n",
            " GPU detected: |   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "RAM available: 11.4 gb/ 12.7 GB total\n",
            "Runtime disk: 194.1 GB free / 235.7 GB total\n",
            "Drive storage: 2TB (psutil cannot read network drives accurately)\n",
            "Verify manually at drive.google.com\n",
            "Drive storage: 184.4 GB free / 235.7 GB total\n",
            "\n",
            "==================================================\n",
            "Session ready. Project root: /content/drive/MyDrive/kidney-tumour-detection\n"
          ]
        }
      ],
      "source": [
        "# DRIVE MOUNT AND ENVIRONMENT VERIFICATION\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# --- Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted.\")\n",
        "\n",
        "# --- Verify project folder exists on Drive ---\n",
        "PROJECT_ROOT = '/content/drive/MyDrive/kidney-tumour-detection'\n",
        "\n",
        "required_folders = [\n",
        "    'dataset/raw',\n",
        "    'dataset/processed',\n",
        "    'checkpoints',\n",
        "    'logs',\n",
        "    'outputs'\n",
        "]\n",
        "\n",
        "print(\"Verifying folder structure...\")\n",
        "all_good = True\n",
        "for folder in required_folders:\n",
        "  full_path = os.path.join(PROJECT_ROOT, folder)\n",
        "  if os.path.exists(full_path):\n",
        "    print(f\" {folder}\")\n",
        "  else:\n",
        "    print(f\" {folder} missing, creating it now...\")\n",
        "    os.mkdirs(full_path, exist_ok = True)\n",
        "    print(f\" {folder} created!\")\n",
        "    all_good = False\n",
        "\n",
        "if all_good:\n",
        "  print(\"All folders have been verified\")\n",
        "else:\n",
        "  print(\"Missing folders have been created\")\n",
        "\n",
        "# --- Check GPU availability ---\n",
        "import subprocess\n",
        "print(\"Checking GPU availability...\")\n",
        "try:\n",
        "  gpu_info = subprocess.run(\n",
        "      ['nvidia-smi'],\n",
        "      capture_output=True,\n",
        "      text=True\n",
        "      )\n",
        "  if gpu_info.returncode == 0:\n",
        "          for line in gpu_info.stdout.split('\\n'):\n",
        "              if any(x in line for x in ['Tesla', 'A100', 'T4', 'V100', 'L4']):\n",
        "                  print(f\" GPU detected: {line.strip()}\")\n",
        "  else:\n",
        "    print(\"nvidia-smi returned an error\")\n",
        "except FileNotFoundError:\n",
        "    print(\"No GPU detected - please change runtime type\")\n",
        "    print(\"Go to: Runtime → Change runtime type → T4 GPU\")\n",
        "except Exception as e:\n",
        "    print(f\" GPU check failed: {e}\")\n",
        "\n",
        "# --- Check RAM ---\n",
        "import psutil\n",
        "ram = psutil.virtual_memory()\n",
        "print(f\"RAM available: {ram.available / (1024**3):.1f} gb\"\n",
        "      f\"/ {ram.total / (1024**3):.1f} GB total\")\n",
        "\n",
        "# --- Check Runtime Disk Usage ---\n",
        "disk = psutil.disk_usage('/')\n",
        "print(f\"Runtime disk: {disk.free / (1024**3):.1f} GB free \"\n",
        "      f\"/ {disk.total / (1024**3):.1f} GB total\")\n",
        "print(\"Drive storage: 2TB (psutil cannot read network drives accurately)\")\n",
        "print(\"Verify manually at drive.google.com\")\n",
        "\n",
        "# --- Check Drive storage ---\n",
        "drive_disk = psutil.disk_usage(PROJECT_ROOT)\n",
        "print(f\"Drive storage: {drive_disk.free / (1024**3):.1f} GB free \"\n",
        "      f\"/ {drive_disk.total / (1024**3):.1f} GB total\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Session ready. Project root:\", PROJECT_ROOT)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GITHUB REPOSITORY SYNC\n",
        "\n",
        "import os\n",
        "\n",
        "GITHUB_REPO = \"https://github.com/danokundaye/kidney-tumour-detection.git\"\n",
        "REPO_NAME = \"kidney-tumour-detection\"\n",
        "CLONE_PATH = f\"/content/{REPO_NAME}\"\n",
        "\n",
        "# --- Clone or update repository ---\n",
        "if os.path.exists(CLONE_PATH):\n",
        "  print(\"Repository already exists, pulling latest changes...\")\n",
        "  os.chdir(CLONE_PATH)\n",
        "  os.system(\"git pull origin main\")\n",
        "  print(\"Repository updated\")\n",
        "else:\n",
        "  print(\"Cloning repository...\")\n",
        "  os.system(f\" git clone {GITHUB_REPO} {CLONE_PATH}\")\n",
        "  print(\"Repository cloned\")\n",
        "\n",
        "# --- Add repo to Python path so we can import our modules ---\n",
        "import sys\n",
        "if CLONE_PATH not in sys.path:\n",
        "    sys.path.insert(0, CLONE_PATH)\n",
        "    print(f\" Added {CLONE_PATH} to Python path\")\n",
        "\n",
        "print(f\"\\nWorking directory: {CLONE_PATH}\")\n",
        "print(\"GitHub sync complete\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTul3MwWJ1Hl",
        "outputId": "3515beaa-c81a-47dd-b745-18fc532715ca",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning repository...\n",
            "Repository cloned\n",
            " Added /content/kidney-tumour-detection to Python path\n",
            "\n",
            "Working directory: /content/kidney-tumour-detection\n",
            "GitHub sync complete\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# INSTALL REQUIRED LIBRARIES\n",
        "\n",
        "print(\"Installing required libraries...\")\n",
        "print(\"This will take 3-5 minutes. Stay calm.\")\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "  subprocess.check_call(\n",
        "      [sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"],\n",
        "      stdout=subprocess.DEVNULL,\n",
        "      stderr=subprocess.DEVNULL\n",
        "  )\n",
        "\n",
        "# Verify PyTorch has already been installed\n",
        "print(\" Checking PyTorch...\", end=\" \")\n",
        "try:\n",
        "    import torch\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"already installed (v{torch.__version__})\")\n",
        "    else:\n",
        "        print(\"Installed but no CUDA - check runtime type\")\n",
        "except ImportError:\n",
        "    print(\"Not found, installing...\")\n",
        "    subprocess.check_call(\n",
        "        [sys.executable, \"-m\", \"pip\", \"install\",\n",
        "         \"torch\", \"torchvision\", \"-q\"]\n",
        "    )\n",
        "    print(\"Installed\")\n",
        "\n",
        "libraries = [\n",
        "    (\"ultralytics\",                               \"YOLOv8\"),\n",
        "    (\"segmentation-models-pytorch\",               \"U-Net with ResNet50\"),\n",
        "    (\"monai\",                                     \"Medical imaging utilities\"),\n",
        "    (\"nibabel\",                                   \"NIfTI file reading\"),\n",
        "    (\"albumentations\",                            \"Data augmentation\"),\n",
        "    (\"shap\",                                      \"Explainability\"),\n",
        "    (\"opencv-python-headless\",                    \"Image processing\"),\n",
        "    (\"scikit-learn\",                              \"Metrics\"),\n",
        "    (\"matplotlib\",                                \"Matplotlib\"),\n",
        "    (\"seaborn\",                                   \"Seaborn\"),\n",
        "    (\"tqdm\",                                      \"Progress bars\"),\n",
        "]\n",
        "\n",
        "for package, name in libraries:\n",
        "  print(f\" Installing {name}...\", end=\" \")\n",
        "  try:\n",
        "    install(package)\n",
        "    print(\"installed\")\n",
        "  except Exception as e:\n",
        "    print(f\" Failed: {e}\")\n",
        "\n",
        "print(\"\\nVerifying critical imports...\")\n",
        "verification = {\n",
        "    \"torch\":                      \"PyTorch\",\n",
        "    \"torchvision\":                \"TorchVision\",\n",
        "    \"ultralytics\":                \"YOLOv8\",\n",
        "    \"segmentation_models_pytorch\":\"U-Net\",\n",
        "    \"monai\":                      \"MONAI\",\n",
        "    \"nibabel\":                    \"NiBabel\",\n",
        "    \"albumentations\":             \"Albumentations\",\n",
        "    \"shap\":                       \"SHAP\",\n",
        "    \"cv2\":                        \"OpenCV\",\n",
        "    \"sklearn\":                    \"Scikit-learn\",\n",
        "}\n",
        "\n",
        "all_imported = True\n",
        "for module, name in verification.items():\n",
        "  try:\n",
        "    __import__(module)\n",
        "    print(f\" {name}\")\n",
        "  except ImportError:\n",
        "    print(f\" {name} - FAILED TO IMPORT\")\n",
        "    all_imported = False\n",
        "\n",
        "if all_imported:\n",
        "    print(\"\\nAll libraries installed and verified\")\n",
        "else:\n",
        "    print(\"\\nSome libraries failed - rerun this cell\")\n",
        "\n",
        "# Verify PyTorch access to GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / (1024**3):.1f} GB\")\n",
        "else:\n",
        "    print(\"CUDA not available - check runtime type\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK4C-z4AYUiS",
        "outputId": "7bfd47c9-cdbf-4fea-e3ca-f52c7c719cd3",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required libraries...\n",
            "This will take 3-5 minutes. Stay calm.\n",
            " Checking PyTorch... already installed (v2.9.0+cu128)\n",
            " Installing YOLOv8... installed\n",
            " Installing U-Net with ResNet50... installed\n",
            " Installing Medical imaging utilities... installed\n",
            " Installing NIfTI file reading... installed\n",
            " Installing Data augmentation... installed\n",
            " Installing Explainability... installed\n",
            " Installing Image processing... installed\n",
            " Installing Metrics... installed\n",
            " Installing Matplotlib... installed\n",
            " Installing Seaborn... installed\n",
            " Installing Progress bars... installed\n",
            "\n",
            "Verifying critical imports...\n",
            " PyTorch\n",
            " TorchVision\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            " YOLOv8\n",
            " U-Net\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<frozen importlib._bootstrap_external>:1301: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " MONAI\n",
            " NiBabel\n",
            " Albumentations\n",
            " SHAP\n",
            " OpenCV\n",
            " Scikit-learn\n",
            "\n",
            "All libraries installed and verified\n",
            "GPU: Tesla T4\n",
            "VRAM: 14.6 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone official KiTS21 Repository\n",
        "\n",
        "import os\n",
        "\n",
        "# Define paths for download\n",
        "DRIVE_PROJECT = \"/content/drive/MyDrive/kidney-tumour-detection\"\n",
        "DATASET_RAW = os.path.join(DRIVE_PROJECT, \"dataset\", \"raw\")\n",
        "KITS_REPO = \"/content/kits21\" # Temporary code storage\n",
        "\n",
        "# Clone the KiTS21 repository into KITS_REPO\n",
        "if not os.path.exists(KITS_REPO):\n",
        "  !git clone https://github.com/neheller/kits21.git /content/kits21\n",
        "  print(\"KiTS21 repository successfully cloned!\")\n",
        "else:\n",
        "  print(\"KiTS21 repository already exists\")\n",
        "\n",
        "# Install package\n",
        "%cd /content/kits21\n",
        "!pip install -e . -q\n",
        "print(\"KiTS21 package installed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3f1KbGhtkCSf",
        "outputId": "d96dc9b6-e6f4-48da-e69a-877c6b53af16"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '/content/kits21'...\n",
            "remote: Enumerating objects: 87173, done.\u001b[K\n",
            "remote: Counting objects: 100% (1155/1155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (570/570), done.\u001b[K\n",
            "remote: Total 87173 (delta 556), reused 1109 (delta 545), pack-reused 86018 (from 1)\u001b[K\n",
            "Receiving objects: 100% (87173/87173), 1.89 GiB | 19.18 MiB/s, done.\n",
            "Resolving deltas: 100% (33701/33701), done.\n",
            "Updating files: 100% (18187/18187), done.\n",
            "KiTS21 repository successfully cloned!\n",
            "/content/kits21\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.3/156.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "KiTS21 package installed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Confirm number of cases\n",
        "cases = [item for item in os.listdir(\"/content/kits21/kits21/data\") if item.startswith(\"case_\")]\n",
        "print(f\"Total cases found: {len(cases)} \\n\")\n",
        "\n",
        "# Confirm case contents\n",
        "sample_case = \"/content/kits21/kits21/data/case_00000\"\n",
        "for item in os.listdir(sample_case):\n",
        "    print(f\"{item}\")\n",
        "\n",
        "# Confirm raw folder contents\n",
        "print(\"\\n--- raw folder ---\")\n",
        "raw_path = os.path.join(sample_case, \"raw\")\n",
        "for item in os.listdir(raw_path):\n",
        "    print(item)\n",
        "\n",
        "# Confirm segmentation folder contents\n",
        "print(\"\\n--- segmentations folder ---\")\n",
        "seg_path = os.path.join(sample_case, \"segmentations\")\n",
        "for item in os.listdir(seg_path):\n",
        "    print(item)\n",
        "\n",
        "download_path = \"/content/kits21/kits21/data\"\n",
        "# Check if there's a download script\n",
        "for root, dirs, files in os.walk(\"/content/kits21/kits21\"):\n",
        "    for file in files:\n",
        "        if \"download\" in file.lower():\n",
        "            print(os.path.join(root, file))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uVlQOJOPqw_p",
        "outputId": "34a08b1d-6f68-4781-cfd3-c4a036af7d9d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total cases found: 300 \n",
            "\n",
            "aggregated_OR_seg.nii.gz\n",
            "aggregated_AND_seg.nii.gz\n",
            "raw\n",
            "aggregated_MAJ_seg.nii.gz\n",
            "segmentations\n",
            "\n",
            "--- raw folder ---\n",
            "tumor\n",
            "ureter\n",
            "kidney\n",
            "artery\n",
            "vein\n",
            "meta.json\n",
            "full\n",
            "\n",
            "--- segmentations folder ---\n",
            "kidney_instance-1_annotation-2.nii.gz\n",
            "kidney_instance-1_annotation-3.nii.gz\n",
            "kidney_instance-2_annotation-2.nii.gz\n",
            "kidney_instance-2_annotation-1.nii.gz\n",
            "tumor_instance-1_annotation-3.nii.gz\n",
            "tumor_instance-1_annotation-1.nii.gz\n",
            "kidney_instance-1_annotation-1.nii.gz\n",
            "tumor_instance-1_annotation-2.nii.gz\n",
            "kidney_instance-2_annotation-3.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Redirect TRAINING_DIR to Google Drive to save downloads permanently\n",
        "paths_file = \"/content/kits21/kits21/configuration/paths.py\"\n",
        "\n",
        "new_content = '''from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Redirected to Google Drive for permanent storage\n",
        "TRAINING_DIR = Path(\"/content/drive/MyDrive/kidney-tumour-detection/dataset/raw\")\n",
        "TESTING_DIR = Path(os.environ[\"KITS21_TEST_DIR\"]).resolve(strict=True) if \"KITS21_TEST_DIR\" in os.environ.keys() else None\n",
        "SRC_DIR = Path(os.environ[\"KITS21_SERVER_DATA\"]).resolve(strict=True) if \"KITS21_SERVER_DATA\" in os.environ.keys() else None\n",
        "CACHE_FILE = Path(__file__).parent.parent / \"annotation\" / \"cache.json\"\n",
        "'''\n",
        "\n",
        "with open(paths_file, \"w\") as f:\n",
        "    f.write(new_content)\n",
        "\n",
        "print(\"TRAINING_DIR redirected to Drive\")\n",
        "\n",
        "# Verify the change\n",
        "with open(paths_file, \"r\") as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h3ZyBXizrfeV",
        "outputId": "1fdcfe69-9f98-423e-b4bc-dde3fe3caf4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAINING_DIR redirected to Drive\n",
            "from pathlib import Path\n",
            "import os\n",
            "\n",
            "# Redirected to Google Drive for permanent storage\n",
            "TRAINING_DIR = Path(\"/content/drive/MyDrive/kidney-tumour-detection/dataset/raw\")\n",
            "TESTING_DIR = Path(os.environ[\"KITS21_TEST_DIR\"]).resolve(strict=True) if \"KITS21_TEST_DIR\" in os.environ.keys() else None\n",
            "SRC_DIR = Path(os.environ[\"KITS21_SERVER_DATA\"]).resolve(strict=True) if \"KITS21_SERVER_DATA\" in os.environ.keys() else None\n",
            "CACHE_FILE = Path(__file__).parent.parent / \"annotation\" / \"cache.json\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy existing case folders in Temporary Storage to Google Drive\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "SOURCE_DIR = \"/content/kits21/kits21/data\"\n",
        "DEST_DIR = \"/content/drive/MyDrive/kidney-tumour-detection/dataset/raw\"\n",
        "\n",
        "# Get all case folders\n",
        "cases = sorted([c for c in os.listdir(SOURCE_DIR) if c.startswith(\"case_\")])\n",
        "print(f\"Cases to copy: {len(cases)}\")\n",
        "\n",
        "for case in tqdm(cases, desc=\"Copying cases to Drive\"):\n",
        "    src = os.path.join(SOURCE_DIR, case)\n",
        "    dst = os.path.join(DEST_DIR, case)\n",
        "\n",
        "    # Only copy if not already in Drive\n",
        "    if not os.path.exists(dst):\n",
        "      shutil.copytree(src, dst)\n",
        "\n",
        "print(f\"\\n All cases copied to Drive\")\n",
        "print(f\"Contents of Drive raw folder:\")\n",
        "print(len(os.listdir(DEST_DIR)), \"items\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gbp3mmsp4dV2",
        "outputId": "8832c282-a657-4e1c-f9d1-10ef55570e9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cases to copy: 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying cases to Drive: 100%|██████████| 300/300 [00:00<00:00, 3031.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " All cases copied to Drive\n",
            "Contents of Drive raw folder:\n",
            "300 items\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify all 300 cases and their contents are on Drive\n",
        "\n",
        "import os\n",
        "\n",
        "DEST_DIR = \"/content/drive/MyDrive/kidney-tumour-detection/dataset/raw\"\n",
        "\n",
        "# Count case folders\n",
        "cases_on_drive = sorted([\n",
        "    item for item in os.listdir(DEST_DIR)\n",
        "    if item.startswith(\"case_\")\n",
        "])\n",
        "\n",
        "print(f\"Total case folders on Drive: {len(cases_on_drive)}\")\n",
        "print(f\"First case: {cases_on_drive[0]}\")\n",
        "print(f\"Last case: {cases_on_drive[-1]}\")\n",
        "\n",
        "# Also verify case_00000 has its contents\n",
        "sample = os.path.join(DEST_DIR, \"case_00000\")\n",
        "print(f\"\\nContents of case_00000 on Drive:\")\n",
        "for item in os.listdir(sample):\n",
        "    print(f\"  {item}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5DOJIi0__Ml",
        "outputId": "5c403576-74e5-441c-d0e7-7d4a2b42dfd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total case folders on Drive: 300\n",
            "First case: case_00000\n",
            "Last case: case_00299\n",
            "\n",
            "Contents of case_00000 on Drive:\n",
            "  aggregated_OR_seg.nii.gz\n",
            "  aggregated_MAJ_seg.nii.gz\n",
            "  segmentations\n",
            "  raw\n",
            "  aggregated_AND_seg.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download CT Scans to Drive\n",
        "\n",
        "import os\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/kits21\")\n",
        "\n",
        "from pathlib import Path\n",
        "from kits21.configuration.paths import TRAINING_DIR\n",
        "import requests\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Verify TRAINING_DIR destination in Drive\n",
        "print(f\"Download destination: {TRAINING_DIR}\")\n",
        "assert \"drive\" in str(TRAINING_DIR), \"TRAINING_DIR is not pointing to Drive! Stop and fix this.\"\n",
        "\n",
        "imaging_url = \"https://kits19.sfo2.digitaloceanspaces.com/\"\n",
        "imaging_name_tmplt =  \"master_{:05d}.nii.gz\"\n",
        "temp_f = Path(\"/content/temp.tmp\")\n",
        "\n",
        "def get_destination(i):\n",
        "    return TRAINING_DIR / \"case_{:05d}\".format(i) / \"imaging.nii.gz\"\n",
        "\n",
        "def download_case(cid):\n",
        "   remote_name = imaging_name_tmplt.format(cid)\n",
        "   url = imaging_url + remote_name\n",
        "   dst = get_destination(cid)\n",
        "   try:\n",
        "    with requests.get(url, stream = True) as r:\n",
        "      r.raise_for_status()\n",
        "      with temp_f.open('wb') as f:\n",
        "        shutil.copyfileobj(r.raw, f)\n",
        "    shutil.move(str(temp_f), str(dst))\n",
        "    return True\n",
        "   except Exception as e:\n",
        "    if temp_f.exists():\n",
        "      temp_f.unlink()\n",
        "    print(f\"\\n Case {cid:05d} failed: {e}\")\n",
        "    return False\n",
        "\n",
        "# Find cases still needing download\n",
        "left_to_download = []\n",
        "for i in range(300):\n",
        "  dst = get_destination(i)\n",
        "  if not dst.exists():\n",
        "    left_to_download.append(i)\n",
        "\n",
        "print(f\"Cases already downloaded: {300 - len(left_to_download)}\")\n",
        "print(f\"Cases remaining: {len(left_to_download)}\")\n",
        "print(f\"Starting download...\\n\")\n",
        "\n",
        "failed = []\n",
        "for i, cid in enumerate(tqdm(left_to_download, desc=\"Downloading CT scans\")):\n",
        "    success = download_case(cid)\n",
        "    if not success:\n",
        "        failed.append(cid)\n",
        "\n",
        "print(f\"\\n Download complete\")\n",
        "print(f\"Successful: {len(left_to_download) - len(failed)}\")\n",
        "print(f\"Failed: {len(failed)}\")\n",
        "if failed:\n",
        "    print(f\"Failed cases: {failed}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfElrHmGsHfl",
        "outputId": "88ba516e-b3db-4cee-c466-dd934cebcf85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download destination: /content/drive/MyDrive/kidney-tumour-detection/dataset/raw\n",
            "Cases already downloaded: 0\n",
            "Cases remaining: 300\n",
            "Starting download...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading CT scans: 100%|██████████| 300/300 [10:46<00:00,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Download complete\n",
            "Successful: 300\n",
            "Failed: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}